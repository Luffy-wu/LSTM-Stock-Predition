{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins\n",
      "train epoch: 0, test accuracy: 0.337862, loss: 1.59902\n",
      "train epoch: 1, test accuracy: 0.387681, loss: 1.55574\n",
      "train epoch: 2, test accuracy: 0.384964, loss: 1.52739\n",
      "train epoch: 3, test accuracy: 0.432971, loss: 1.50312\n",
      "train epoch: 4, test accuracy: 0.471014, loss: 1.48233\n",
      "train epoch: 5, test accuracy: 0.505435, loss: 1.46338\n",
      "train epoch: 6, test accuracy: 0.528986, loss: 1.44363\n",
      "train epoch: 7, test accuracy: 0.5625, loss: 1.42346\n",
      "train epoch: 8, test accuracy: 0.589674, loss: 1.40088\n",
      "train epoch: 9, test accuracy: 0.628623, loss: 1.37649\n",
      "train epoch: 10, test accuracy: 0.65308, loss: 1.34746\n",
      "train epoch: 11, test accuracy: 0.65942, loss: 1.3169\n",
      "train epoch: 12, test accuracy: 0.672101, loss: 1.28326\n",
      "train epoch: 13, test accuracy: 0.67663, loss: 1.25174\n",
      "train epoch: 14, test accuracy: 0.678442, loss: 1.22229\n",
      "train epoch: 15, test accuracy: 0.684783, loss: 1.19501\n",
      "train epoch: 16, test accuracy: 0.688406, loss: 1.17259\n",
      "train epoch: 17, test accuracy: 0.694746, loss: 1.15297\n",
      "train epoch: 18, test accuracy: 0.696558, loss: 1.13952\n",
      "train epoch: 19, test accuracy: 0.696558, loss: 1.12598\n",
      "train epoch: 20, test accuracy: 0.700181, loss: 1.11728\n",
      "train epoch: 21, test accuracy: 0.700181, loss: 1.10885\n",
      "train epoch: 22, test accuracy: 0.69837, loss: 1.1022\n",
      "train epoch: 23, test accuracy: 0.701087, loss: 1.09557\n",
      "train epoch: 24, test accuracy: 0.702899, loss: 1.09148\n",
      "train epoch: 25, test accuracy: 0.711051, loss: 1.08843\n",
      "train epoch: 26, test accuracy: 0.709239, loss: 1.08295\n",
      "train epoch: 27, test accuracy: 0.710145, loss: 1.07945\n",
      "train epoch: 28, test accuracy: 0.717391, loss: 1.07611\n",
      "train epoch: 29, test accuracy: 0.719203, loss: 1.07386\n",
      "train epoch: 30, test accuracy: 0.725543, loss: 1.07082\n",
      "train epoch: 31, test accuracy: 0.725543, loss: 1.06965\n",
      "train epoch: 32, test accuracy: 0.726449, loss: 1.06581\n",
      "train epoch: 33, test accuracy: 0.724638, loss: 1.0655\n",
      "train epoch: 34, test accuracy: 0.727355, loss: 1.06234\n",
      "train epoch: 35, test accuracy: 0.724638, loss: 1.06061\n",
      "train epoch: 36, test accuracy: 0.723732, loss: 1.05973\n",
      "train epoch: 37, test accuracy: 0.727355, loss: 1.05716\n",
      "train epoch: 38, test accuracy: 0.727355, loss: 1.05577\n",
      "train epoch: 39, test accuracy: 0.730072, loss: 1.05323\n",
      "train epoch: 40, test accuracy: 0.730072, loss: 1.05214\n",
      "train epoch: 41, test accuracy: 0.731884, loss: 1.0508\n",
      "train epoch: 42, test accuracy: 0.73279, loss: 1.05038\n",
      "train epoch: 43, test accuracy: 0.733696, loss: 1.04871\n",
      "train epoch: 44, test accuracy: 0.73279, loss: 1.0471\n",
      "train epoch: 45, test accuracy: 0.73279, loss: 1.04738\n",
      "train epoch: 46, test accuracy: 0.731884, loss: 1.04464\n",
      "train epoch: 47, test accuracy: 0.734601, loss: 1.04315\n",
      "train epoch: 48, test accuracy: 0.73279, loss: 1.04463\n",
      "train epoch: 49, test accuracy: 0.735507, loss: 1.04446\n",
      "train epoch: 50, test accuracy: 0.734601, loss: 1.04158\n",
      "train epoch: 51, test accuracy: 0.737319, loss: 1.03991\n",
      "train epoch: 52, test accuracy: 0.73279, loss: 1.03939\n",
      "train epoch: 53, test accuracy: 0.730978, loss: 1.03717\n",
      "train epoch: 54, test accuracy: 0.731884, loss: 1.03515\n",
      "train epoch: 55, test accuracy: 0.730072, loss: 1.03643\n",
      "train epoch: 56, test accuracy: 0.730978, loss: 1.03583\n",
      "train epoch: 57, test accuracy: 0.733696, loss: 1.03552\n",
      "train epoch: 58, test accuracy: 0.731884, loss: 1.03604\n",
      "train epoch: 59, test accuracy: 0.734601, loss: 1.0348\n",
      "train epoch: 60, test accuracy: 0.736413, loss: 1.03505\n",
      "train epoch: 61, test accuracy: 0.73279, loss: 1.03496\n",
      "train epoch: 62, test accuracy: 0.734601, loss: 1.03426\n",
      "train epoch: 63, test accuracy: 0.731884, loss: 1.03224\n",
      "train epoch: 64, test accuracy: 0.731884, loss: 1.03005\n",
      "train epoch: 65, test accuracy: 0.734601, loss: 1.03298\n",
      "train epoch: 66, test accuracy: 0.733696, loss: 1.02988\n",
      "train epoch: 67, test accuracy: 0.734601, loss: 1.02871\n",
      "train epoch: 68, test accuracy: 0.731884, loss: 1.028\n",
      "train epoch: 69, test accuracy: 0.73279, loss: 1.02719\n",
      "train epoch: 70, test accuracy: 0.733696, loss: 1.02722\n",
      "train epoch: 71, test accuracy: 0.735507, loss: 1.03002\n",
      "train epoch: 72, test accuracy: 0.736413, loss: 1.03072\n",
      "train epoch: 73, test accuracy: 0.73279, loss: 1.02736\n",
      "train epoch: 74, test accuracy: 0.731884, loss: 1.02441\n",
      "train epoch: 75, test accuracy: 0.735507, loss: 1.02485\n",
      "train epoch: 76, test accuracy: 0.730978, loss: 1.022\n",
      "train epoch: 77, test accuracy: 0.733696, loss: 1.02218\n",
      "train epoch: 78, test accuracy: 0.736413, loss: 1.02299\n",
      "train epoch: 79, test accuracy: 0.734601, loss: 1.02187\n",
      "train epoch: 80, test accuracy: 0.736413, loss: 1.0232\n",
      "train epoch: 81, test accuracy: 0.735507, loss: 1.02261\n",
      "train epoch: 82, test accuracy: 0.734601, loss: 1.02028\n",
      "train epoch: 83, test accuracy: 0.734601, loss: 1.01943\n",
      "train epoch: 84, test accuracy: 0.736413, loss: 1.02053\n",
      "train epoch: 85, test accuracy: 0.737319, loss: 1.02079\n",
      "train epoch: 86, test accuracy: 0.737319, loss: 1.02066\n",
      "train epoch: 87, test accuracy: 0.736413, loss: 1.01707\n",
      "train epoch: 88, test accuracy: 0.737319, loss: 1.01751\n",
      "train epoch: 89, test accuracy: 0.737319, loss: 1.01676\n",
      "train epoch: 90, test accuracy: 0.734601, loss: 1.01489\n",
      "train epoch: 91, test accuracy: 0.734601, loss: 1.01334\n",
      "train epoch: 92, test accuracy: 0.733696, loss: 1.01313\n",
      "train epoch: 93, test accuracy: 0.735507, loss: 1.01406\n",
      "train epoch: 94, test accuracy: 0.737319, loss: 1.01546\n",
      "train epoch: 95, test accuracy: 0.737319, loss: 1.01528\n",
      "train epoch: 96, test accuracy: 0.737319, loss: 1.01397\n",
      "train epoch: 97, test accuracy: 0.735507, loss: 1.01277\n",
      "train epoch: 98, test accuracy: 0.738225, loss: 1.01287\n",
      "train epoch: 99, test accuracy: 0.735507, loss: 1.01259\n",
      "final test accuracy: 0.735507\n",
      "best epoch's test accuracy: 0.738225\n",
      "---end---\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#define class Stock to pass parameters conveniently\n",
    "class Stock():\n",
    "    def _init_(self):\n",
    "        # define the parameters for model\n",
    "        self.training_epochs = 100\n",
    "        self.batch_size = 1500\n",
    "        self.learning_rate = 0.00003 \n",
    "        self.loss_para = 0.0015\n",
    "        \n",
    "        self.hidden_layers = 32  \n",
    "        self.out_layers = 3  \n",
    "        #path for data input \n",
    "        input_types= [\"open.txt\",\"high.txt\",\"low.txt\",\"close.txt\",\n",
    "                          \"volume.txt\",\"amt.txt\",\"pct_chg.txt\",\"turn.txt\"]\n",
    "        self.xtrain_paths = [\"/Users/luffy/Desktop/DL/data/hushen3002/data_experiment/train/\"\n",
    "                             + \"train_\" + i for i in input_types]\n",
    "        self.xtest_paths = [\"/Users/luffy/Desktop/DL/data/hushen3002/data_experiment/test/\"\n",
    "                             + \"test_\" + i for i in input_types]\n",
    "        self.ytrain_path = \"/Users/luffy/Desktop/DL/data/hushen3002/data_experiment/train/y_train.txt\"\n",
    "        self.ytest_path = \"/Users/luffy/Desktop/DL/data/hushen3002/data_experiment/test/y_test.txt\"\n",
    "    \n",
    "    #Input data\n",
    "    def xload(self,xpaths):\n",
    "        X = []\n",
    "        for path_ in xpaths:\n",
    "            file = open(path_, 'r',encoding='utf-16')\n",
    "            X.append([np.array(i, dtype=np.float32) for i in \n",
    "                       [row.replace('\\t', ' ').strip().split(' ') for row in file]])\n",
    "            file.close()\n",
    "        return np.transpose(np.array(X), (1, 2, 0))\n",
    "\n",
    "    def yload(self,ypath):\n",
    "        file = open(ypath, 'r',encoding='utf-16')\n",
    "        y = np.array(\n",
    "        [i for i in [row.replace('\\t', ' ').strip().split(' ') for row in file]],dtype=np.int32)\n",
    "        file.close()\n",
    "        return y - 1\n",
    "    \n",
    "    #Transform the label to one-hot values\n",
    "    #eg: [2] --> [0, 0, 1]\n",
    "    def one_hot(self,y):\n",
    "        y = y.reshape(len(y))\n",
    "        temp = int(np.max(y)) + 1\n",
    "        return np.eye(temp)[np.array(y, dtype=np.int32)]  \n",
    "\n",
    "    def LSTM_Network(self,X): #Construct LSTM model\n",
    "        self.weight_hidden=tf.Variable(tf.random_normal([self.input_num, self.hidden_layers]))\n",
    "        self.weight_output=tf.Variable(tf.random_normal([self.hidden_layers, self.out_layers]))\n",
    "        \n",
    "        self.biases_hidden = tf.Variable(tf.random_normal([self.hidden_layers], mean=1.0))\n",
    "        self.biases_output = tf.Variable(tf.random_normal([self.out_layers]))\n",
    "        tf.summary.histogram('weight_hidden', self.weight_hidden)\n",
    "        tf.summary.histogram('weight_output', self.weight_output)\n",
    "        tf.summary.histogram('biase_hidden', self.biases_hidden)\n",
    "        tf.summary.histogram('biase_output', self.biases_output)\n",
    "        \n",
    "        # Reshape X for input,dimension_num*batch_size, n_input\n",
    "        X = tf.transpose(X, [1, 0, 2])  \n",
    "        X = tf.reshape(X, [-1, self.input_num])\n",
    "        # Define two LSTM cells\n",
    "        X = tf.nn.relu(tf.matmul(X, self.weight_hidden) + self.biases_hidden)\n",
    "        X = tf.split(X, self.dimension_num, 0)\n",
    "        lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(self.hidden_layers, forget_bias=1.0, state_is_tuple=True)\n",
    "        lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(self.hidden_layers, forget_bias=1.0, state_is_tuple=True)\n",
    "        lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "        outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, X, dtype=tf.float32)\n",
    "        return tf.matmul(outputs[-1], self.weight_output) + self.biases_output\n",
    "\n",
    "    def train(self):\n",
    "        self._init_()\n",
    "        #input data\n",
    "        self.xtrain = self.xload(self.xtrain_paths)\n",
    "        self.xtest = self.xload(self.xtest_paths)\n",
    "        self.ytrain = self.one_hot(self.yload(self.ytrain_path))\n",
    "        self.ytest = self.one_hot(self.yload(self.ytest_path))\n",
    "        self.train_num = len(self.xtrain)  \n",
    "        self.dimension_num = len(self.xtrain[0])  \n",
    "        self.input_num = len(self.xtrain[0][0]) \n",
    "        \n",
    "        X = tf.placeholder(tf.float32, [None, self.dimension_num, self.input_num])\n",
    "        Y = tf.placeholder(tf.float32, [None, self.out_layers])\n",
    "        y_ = self.LSTM_Network(X)\n",
    "        \n",
    "        #Using regularization to avoid over-fitting\n",
    "        L = self.loss_para * sum(tf.nn.l2_loss(i) for i in tf.trainable_variables())\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=y_)) + L \n",
    "        tf.summary.scalar('loss', cost)\n",
    "        #optimizer,evaluation\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(cost)\n",
    "        prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(prediction, dtype=tf.float32))\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        merged = tf.summary.merge_all()\n",
    "        sess = tf.InteractiveSession()\n",
    "        log_dir='/Users/luffy/Desktop/DL/tensorboard/'\n",
    "        train_writer = tf.summary.FileWriter(log_dir+'train/', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(log_dir+'test/')\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        # train\n",
    "        optimal_accuracy = 0.0\n",
    "        index=[i for i in range(len(self.ytrain))]\n",
    "        print(\"Training begins\")\n",
    "        j=0\n",
    "        for i in range(self.training_epochs):\n",
    "            np.random.shuffle(index)\n",
    "            for begin, end in zip(range(0, self.train_num, self.batch_size),\n",
    "                                  range(self.batch_size, self.train_num + 1, self.batch_size)):\n",
    "                temp=index[begin:end]\n",
    "                j += 1\n",
    "                _,train_summary =sess.run([optimizer,merged], feed_dict={X: self.xtrain[temp],Y: self.ytrain[temp]})\n",
    "                train_writer.add_summary(train_summary, j)\n",
    "            #print the train result for each epoch\n",
    "            y_pred, acc_result, loss_result,test_summary = sess.run(\n",
    "            [y_, accuracy, cost,merged],feed_dict={X: self.xtest,Y: self.ytest})\n",
    "            test_writer.add_summary(test_summary, i)\n",
    "            print(\"train epoch: %d, test accuracy: %g, loss: %g\"%(i,acc_result,loss_result))\n",
    "            optimal_accuracy = max(optimal_accuracy, acc_result)\n",
    "        train_writer.close()\n",
    "        test_writer.close()\n",
    "        print(\"final test accuracy: %g\"%(acc_result))\n",
    "        print(\"best epoch's test accuracy: %g\"%(optimal_accuracy))\n",
    "        print(\"---end---\")\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stock=Stock()\n",
    "    stock.train()\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luffy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "TensorBoard 1.6.0 at http://lixiangwus-MacBook-Air.local:6006 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir='/Users/luffy/Desktop/DL/tensorboard/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://localhost:6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
